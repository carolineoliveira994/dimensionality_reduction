{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMisKuJmysEO1H/K5Jf0OrI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carolineoliveira994/dimensionality_reduction/blob/main/pca_base_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUxSF2GGCV5n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "atualemnte, diferentes tipos de dados possuem umg rande númerod de features/dimensões\n",
        "\n",
        "para deduzir o numero de dimensoes que os dados tem, os numeros de coluna\n",
        "mapeando de um espaço para outro espaço\n",
        "a redução de dimensionalidade faz um proceso de transformação de dados para mapear para um espaço reduzido demobnstrativo dos dados\n",
        "\n",
        "(explicar resultas para alguem (e.g. clustering))\n",
        "\n",
        "Curse of dimensionality\n",
        "nossa perfomance possui um pico, onde add novas features nao ajuda\n",
        "\n",
        "se a quantidade de dados de treinamento disponiveis é fixa, o ov erfitting acontece se continuarmos adicionando  dimensões por outro lado\n",
        "\n",
        "supervisionada: Linar discriminant analysis (LDA)\n",
        "Fisher Linear\n",
        "\n",
        "Principal Component analysis (PCA)\n",
        "\n",
        "combinação linar de diferente features (originais), novo conjunbto se chama principle components (PC)\n",
        "\n",
        "\n",
        "PCA - Intuição\n",
        "\n",
        "encontrar uma reta que gal foram que quando osd ados sao proejtos na linha, ela tenha m,axima variancia\n",
        "\n",
        "variancia = espalhamento\n",
        "\n",
        "\n",
        "1. Normalizar os dados para ter média zero e desvio padrão um\n",
        "\n",
        "2. Calcular a matriz de covariãncia (ajuda a entender a correlação entre os dados: variancia;espalahmento dos dados\n",
        "covariancia:orientação (rotação no grafico)\n",
        "\n",
        "\n",
        "\n",
        "3. Calcuçar autovetores decovariancia\n",
        "\n",
        "ajuda a caracterizar os dados, onde os ayutovetores tentam cpturar a variancia dos daods\n",
        "\n",
        "4. selecionar os componentes principais (autovetores)\n",
        "\n",
        "autovetor co m o maior autovalor é o ´rimerio principal component PC1\n",
        "\n",
        "5. realizar a redução da dimensionalidade dos dados\n",
        "slecioanr os k principal componetns\n",
        "pejhtar os dados nos eicos reprsetados pelos k principal com\n",
        "a seleção é feita de talf ormaque k seja o mens vlairo possivel que represete x%\n"
      ],
      "metadata": {
        "id": "VtPGZzdHCecD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (14, 8)\n",
        "\n",
        "sns.set(font_scale=2)"
      ],
      "metadata": {
        "id": "URRXf5f2NKi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/iris.data')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "lh_T5pxeOIVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df[df.columns[:4]]\n",
        "df_labels = df[df.columns[4]]\n",
        "\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "7-qxgmqiRDTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(df_train)"
      ],
      "metadata": {
        "id": "lxCPW9V5Rm_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'variance': pca.explained_variance_ratio_,\n",
        "    'principal_components':['pc1', 'pc2', 'pc3', 'pc4']\n",
        "}\n",
        "\n",
        "df_variance = pd.DataFrame(data)\n",
        "sns.barplot(x='principal_components', y='variance', data=df_variance, color='c');"
      ],
      "metadata": {
        "id": "A4U_FvTsR3UJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_transformed = pca.fit_transform(df_train)\n",
        "df_train_transformed = pd.DataFrame(df_train_transformed, columns=['pc1', 'pc2', 'pc3', 'pc4'])\n",
        "df_train_transformed.head()"
      ],
      "metadata": {
        "id": "gOsXQ_orSlkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_with_principal_components(dim_x, dim_y, df_train):\n",
        "  columns_names = df_train.columns\n",
        "\n",
        "  xs = df_train_transformed[df_train_transformed.columns[dim_x]]\n",
        "  ys = df_train_transformed[df_train_transformed.columns[dim_x]]\n",
        "\n",
        "\n",
        "  color_dict = {\n",
        "      'Iris-setosa': 'blue',\n",
        "      'Iris-versicolor': 'green',\n",
        "      'Iris-virginica': 'orange'\n",
        "      }\n",
        "\n",
        "  for (x, y, l) in zip(xs, ys, df_labels):\n",
        "    _ = plt.scatter(x, y, alpha=0.8, color=color_dict[l])\n",
        "\n",
        "  _ = plt.xlabel(columns_names[dim_x])\n",
        "  _ = plt.ylabel(columns_names[dim_y])\n"
      ],
      "metadata": {
        "id": "OULv_SK0SljH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PC1 E PC2\n",
        "plot_with_principal_components(0, 1, df_train)"
      ],
      "metadata": {
        "id": "6_5JQcwVWHSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_principal_components(0, 2, df_train)"
      ],
      "metadata": {
        "id": "2vLZ-JvWWV_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_principal_components(0, 3, df_train)"
      ],
      "metadata": {
        "id": "rhaS8WjsWWX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_principal_components(0, 1, df_train)"
      ],
      "metadata": {
        "id": "QgmBQnwQWXKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_principal_components(1, 3, df_train)"
      ],
      "metadata": {
        "id": "Qk5gHRmZWXWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bE0t0XnyZHa8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEV7389mc5lP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}